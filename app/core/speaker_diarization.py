import numpy as np
import librosa
import torch
from typing import List, Dict, Tuple, Optional
import tempfile
import os
from pathlib import Path
import json
from datetime import datetime
import soundfile as sf
import io     
import base64  
import requests
from fastapi import HTTPException

try:
    from pyannote.audio import Pipeline
    from pyannote.core import Segment
    PYANNOTE_AVAILABLE = True
except ImportError:
    PYANNOTE_AVAILABLE = False
    print("Warning: pyannote-audio not available. Speaker diarization will use fallback method.")

from pydub import AudioSegment


class SpeakerDiarizer:
    """í™”ìë¶„ë¦¬ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 token: str = "",
                 min_speakers: int = 1, 
                 max_speakers: int = 10,
                 use_pyannote: bool = True,
                 # ğŸ”§ ì¡°ì ˆ íŒŒë¼ë¯¸í„° ì¶”ê°€
                 min_duration_on: float = 1.0,      # ìµœì†Œ ë°œí™” ì‹œê°„     
                 min_duration_off: float = 0.5,     # ìµœì†Œ ì¹¨ë¬µ ì‹œê°„     
                 merge_threshold: float = 2.0):     # ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì„ê³„ê°’

        self.token = token
        self.min_speakers = min_speakers
        self.max_speakers = max_speakers
        self.use_pyannote = use_pyannote and PYANNOTE_AVAILABLE
        
        # ğŸ”§ ì¡°ì ˆ íŒŒë¼ë¯¸í„°
        self.min_duration_on = min_duration_on
        self.min_duration_off = min_duration_off
        self.merge_threshold = merge_threshold
        
        # pyannote íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        if self.use_pyannote:
            try:
                self.pipeline = Pipeline.from_pretrained(
                    "pyannote/speaker-diarization-3.1",
                    use_auth_token=self.token
                )
                print("âœ… pyannote íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì„±ê³µ!")
            except Exception as e:
                print(f"âŒ pyannote íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.use_pyannote = False
    
    def preprocess_audio(self, audio_path: str, target_sr: int = 16000) -> str:
        """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (WAV ìš°ì„ , MP4/MP3 ì§€ì›)"""
        try:
            print(f" ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹œì‘: {audio_path}")
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            file_ext = os.path.splitext(audio_path)[1].lower()
            
            # WAV íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
            if file_ext == '.wav':
                print("âœ… WAV íŒŒì¼ ê°ì§€, ì§ì ‘ ì²˜ë¦¬")
                try:
                    # librosaë¡œ ì§ì ‘ ë¡œë“œ
                    y, sr = librosa.load(audio_path, sr=target_sr, mono=True)
                    
                    # ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥
                    with tempfile.NamedTemporaryFile(suffix="_final.wav", delete=False) as tmp_file:
                        sf.write(tmp_file.name, y, target_sr)
                        print(f"âœ… WAV ì „ì²˜ë¦¬ ì™„ë£Œ: {tmp_file.name}")
                        return tmp_file.name
                        
                except Exception as e:
                    print(f"âš ï¸ WAV ì§ì ‘ ì²˜ë¦¬ ì‹¤íŒ¨, pydubìœ¼ë¡œ ì¬ì‹œë„: {e}")
            
            # MP4/MP3 íŒŒì¼ì¸ ê²½ìš° pydubìœ¼ë¡œ ì²˜ë¦¬
            print(f"ğŸ”„ {file_ext.upper()} íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            audio = AudioSegment.from_file(audio_path)
            
            # librosaê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                # WAV í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (16kHz, ëª¨ë…¸)
                audio.export(tmp_file.name, format="wav", parameters=["-ar", "16000", "-ac", "1"])
                
                # librosaë¡œ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì •í™•í•œ ì²˜ë¦¬ë¥¼ ìœ„í•´
                y, sr = librosa.load(tmp_file.name, sr=target_sr, mono=True)
                
                # ìµœì¢… WAV íŒŒì¼ë¡œ ì €ì¥
                final_file = tmp_file.name.replace('.wav', '_final.wav')
                sf.write(final_file, y, target_sr)
                
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                os.unlink(tmp_file.name)
                
                print(f"âœ… ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì™„ë£Œ: {final_file}")
                return final_file
                
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return audio_path
    
    def post_process_segments(self, segments: List[Dict]) -> List[Dict]:
        """ì„¸ê·¸ë¨¼íŠ¸ í›„ì²˜ë¦¬ - ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©"""
        if not segments:
            return segments
            
        filtered = []
        
        for segment in segments:
            duration = segment['end'] - segment['start']
            
            # ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ë³‘í•©
            if duration < self.merge_threshold and filtered:
                # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ì™€ ê°™ì€ í™”ìë©´ ë³‘í•©
                if filtered[-1]['speaker_id'] == segment['speaker_id']:      
                    filtered[-1]['end'] = segment['end']
                    filtered[-1]['duration'] = filtered[-1]['end'] - filtered[-1]['start']
                    continue
            
            filtered.append(segment)
        
        print(f" ì„¸ê·¸ë¨¼íŠ¸ í›„ì²˜ë¦¬ ì™„ë£Œ: {len(segments)} â†’ {len(filtered)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return filtered
    
    def diarize_speakers(self, audio_path: str) -> List[Dict]:
        """í™”ìë¶„ë¦¬ ìˆ˜í–‰"""
        print(f"ğŸ¯ í™”ìë¶„ë¦¬ ì‹œì‘: {audio_path}")
        
        processed_audio = self.preprocess_audio(audio_path)
        
        try:
            if self.use_pyannote:
                results = self.diarize_with_pyannote(processed_audio)
            else:
                results = self._fallback_diarization(processed_audio)
            
            # ğŸ”§ í›„ì²˜ë¦¬ ì ìš© - ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
            results = self.post_process_segments(results)
            
            print(f"âœ… í™”ìë¶„ë¦¬ ì™„ë£Œ: {len(results)}ê°œ êµ¬ê°„ ë°œê²¬")
            return results
            
        finally:
            if os.path.exists(processed_audio) and processed_audio != audio_path:
                os.unlink(processed_audio)
    
    def diarize_with_pyannote(self, audio_path: str) -> List[Dict]:
        """pyannoteë¥¼ ì‚¬ìš©í•œ í™”ìë¶„ë¦¬"""
        if not self.use_pyannote:
            raise RuntimeError("pyannote not available")
        
        try:
            print(" pyannoteë¡œ í™”ìë¶„ë¦¬ ìˆ˜í–‰ ì¤‘...")
            
            # âœ… ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©
            diarization = self.pipeline(
                audio_path,
                min_speakers=self.min_speakers,
                max_speakers=self.max_speakers
            )
            
            results = []
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                # í™”ì IDë¥¼ ìˆ«ìë¡œ ë³€í™˜ (SPEAKER_00 -> 0, SPEAKER_01 -> 1)
                speaker_id_number = self._extract_speaker_number(speaker)
                
                results.append({
                    "start": turn.start,
                    "end": turn.end,
                    "duration": turn.end - turn.start,
                    "speaker": speaker,
                    "speaker_id": speaker_id_number
                })
            
            return results
            
        except Exception as e:
            print(f"âŒ pyannote í™”ìë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return self._fallback_diarization(audio_path)
    
    def _fallback_diarization(self, audio_path: str) -> List[Dict]:
        """fallback í™”ìë¶„ë¦¬"""
        print(" fallback í™”ìë¶„ë¦¬ ìˆ˜í–‰ ì¤‘...")
        
        try:
            y, sr = librosa.load(audio_path, sr=16000, mono=True)
            intervals = librosa.effects.split(y, top_db=30)
            
            min_duration = 0.5
            filtered_intervals = []
            for start, end in intervals:
                duration = (end - start) / sr
                if duration >= min_duration:
                    filtered_intervals.append({
                        "start": start / sr,
                        "end": end / sr,
                        "duration": duration,
                        "speaker": "SPEAKER_00",
                        "speaker_id": 0
                    })
            
            return filtered_intervals
            
        except Exception as e:
            print(f"âŒ í™”ìë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_speaker_number(self, speaker_id: str) -> int:
        """í™”ì IDì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        try:
            if speaker_id.startswith("SPEAKER_"):
                return int(speaker_id.split("_")[1])
            return 0
        except:
            return 0

    def diarize_audio(self, audio_data: bytes) -> List[Dict]:
        """ë°”ì´íŠ¸ ë°ì´í„°ë¡œë¶€í„° í™”ìë¶„ë¦¬ ìˆ˜í–‰"""
        try:
            # 1. ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                tmp.write(audio_data)
                tmp.flush()
                audio_path = tmp.name
            
            try:
                # 2. ê¸°ì¡´ diarize_speakers ë©”ì„œë“œ ì‚¬ìš©
                results = self.diarize_speakers(audio_path)
                
                # 3. í‚¤ ì´ë¦„ì„ ì˜¬ë°”ë¥´ê²Œ ë³€í™˜
                converted_results = []
                for result in results:
                    converted_results.append({
                        'start_time': result['start'],
                        'end_time': result['end'],
                        'speaker_tag': result['speaker_id']
                    })
                
                return converted_results
                
            finally:
                # 4. ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(audio_path):
                    os.unlink(audio_path)
                    
        except Exception as e:
            print(f"âŒ í™”ìë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def map_speakers_to_mentor_mentee(self, segments: List[Dict], mentor_idx: int, mentee_idx: int) -> List[Dict]:
        """í™”ì ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë©˜í† /ë©˜í‹°ë¡œ ë§¤í•‘"""
        try:
            if not segments:
                return []
            
            # í™”ìë³„ ì´ ë°œí™” ì‹œê°„ ê³„ì‚°
            speaker_times = {}
            for segment in segments:
                speaker_id = segment.get('speaker_tag', 0)
                duration = segment.get('end_time', 0) - segment.get('start_time', 0)
                speaker_times[speaker_id] = speaker_times.get(speaker_id, 0) + duration
            
            # ë” ë§ì´ ë°œí™”í•œ í™”ìë¥¼ ë©˜í† ë¡œ, ì ê²Œ ë°œí™”í•œ í™”ìë¥¼ ë©˜í‹°ë¡œ ë§¤í•‘
            sorted_speakers = sorted(speaker_times.items(), key=lambda x: x[1], reverse=True)
            
            if len(sorted_speakers) >= 2:
                mentor_speaker_id = sorted_speakers[0][0]  # ë” ë§ì´ ë°œí™”
                mentee_speaker_id = sorted_speakers[1][0]  # ì ê²Œ ë°œí™”
            else:
                # í™”ìê°€ 1ëª…ì¸ ê²½ìš°
                mentor_speaker_id = sorted_speakers[0][0] if sorted_speakers else 0
                mentee_speaker_id = mentor_speaker_id
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘
            mapped_segments = []
            for segment in segments:
                speaker_id = segment.get('speaker_tag', 0)
                
                if speaker_id == mentor_speaker_id:
                    mapped_tag = 0  # ë©˜í† 
                elif speaker_id == mentee_speaker_id:
                    mapped_tag = 1  # ë©˜í‹°
                else:
                    # ì˜ˆìƒì¹˜ ëª»í•œ í™”ì IDì¸ ê²½ìš° ê¸°ë³¸ê°’
                    mapped_tag = 0
                
                mapped_segments.append({
                    'start_time': segment.get('start_time', 0),
                    'end_time': segment.get('end_time', 0),
                    'speaker_tag': mapped_tag
                })
            
            print(f" í™”ì ë§¤í•‘ ì™„ë£Œ: ë©˜í† (í™”ì {mentor_speaker_id} â†’ íƒœê·¸ 0), ë©˜í‹°(í™”ì {mentee_speaker_id} â†’ íƒœê·¸ 1)")
            return mapped_segments
            
        except Exception as e:
            print(f"âŒ í™”ì ë§¤í•‘ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (íƒœê·¸ëŠ” 0ìœ¼ë¡œ)
            return [{
                'start_time': seg.get('start_time', 0),
                'end_time': seg.get('end_time', 0),
                'speaker_tag': 0
            } for seg in segments]

    def extract_audio_segment(self, audio_data: bytes, start_time: float, end_time: float) -> bytes:
        """ì˜¤ë””ì˜¤ ë°ì´í„°ì—ì„œ íŠ¹ì • ì‹œê°„ êµ¬ê°„ì„ ì¶”ì¶œí•˜ì—¬ ë²„í¼ë¡œ ë°˜í™˜"""
        try:
            # BytesIOë¡œ ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
            audio_io = io.BytesIO(audio_data)
            
            # pydubìœ¼ë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = AudioSegment.from_file(audio_io)
            
            # ì‹œê°„ì„ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
            start_ms = int(start_time * 1000)
            end_ms = int(end_time * 1000)
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
            segment = audio[start_ms:end_ms]
            
            # WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë²„í¼ ë°˜í™˜
            output_io = io.BytesIO()
            segment.export(output_io, format="wav", parameters=[
               "-ar", "16000",      # 16kHz ìƒ˜í”Œë ˆì´íŠ¸
               "-ac", "1",          # ëª¨ë…¸ (1ì±„ë„)
               "-sample_fmt", "s16" # 16ë¹„íŠ¸ ìƒ˜í”Œ í¬ë§·
               ])
            
            return output_io.getvalue()
            
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return b""


def download_audio_from_gcs(gcs_url: str) -> bytes:
    """GCS URLì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë°”ì´íŠ¸ ë°ì´í„°ë¡œ ë°˜í™˜"""
    try:
        print(f"ğŸ“¥ GCSì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {gcs_url}")
        
        # íƒ€ì„ì•„ì›ƒì„ 10ë¶„ìœ¼ë¡œ ì¦ê°€
        response = requests.get(gcs_url, timeout=600)  # 10ë¶„ (600ì´ˆ)
        response.raise_for_status()
        
        # íŒŒì¼ í¬ê¸° ì²´í¬ (500MB ì œí•œ)
        content_length = len(response.content)
        max_size = 500 * 1024 * 1024  # 500MB
        
        if content_length > max_size:
            raise HTTPException(
                status_code=400, 
                detail=f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {content_length / (1024*1024):.1f}MB (ìµœëŒ€ 500MB)"
            )
        
        print(f"âœ… GCS ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {content_length / (1024*1024):.1f}MB")
        print(f"âœ… GCS ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {content_length} bytes")
        
        # ğŸ” íŒŒì¼ í˜•ì‹ í™•ì¸
        content_type = response.headers.get('content-type', 'unknown')
        print(f" Content-Type: {content_type}")
        
        # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ (ì²« 4ë°”ì´íŠ¸)
        if len(response.content) >= 4:
            file_signature = response.content[:4].hex()
            print(f"ğŸ” íŒŒì¼ ì‹œê·¸ë‹ˆì²˜: {file_signature}")
            
            # WAV íŒŒì¼ í™•ì¸
            if response.content[:4] == b'RIFF':
                print("âœ… WAV íŒŒì¼ ê°ì§€!")
            elif response.content[:4] == b'\x00\x00\x00\x20':
                print("âœ… MP4 íŒŒì¼ ê°ì§€!")
        
        return response.content
        
    except requests.exceptions.Timeout:
        print(f"âŒ GCS ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ: {gcs_url}")
        raise HTTPException(status_code=408, detail="GCS ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼)")
    except Exception as e:
        print(f"âŒ GCS ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=400, detail=f"GCS ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

def process_audio_pipeline(audio_path: str, 
                          token: str = "", 
                          min_speakers: int = 1, 
                          max_speakers: int = 2) -> Dict:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì— ëŒ€í•œ í™”ìë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        token: HuggingFace í† í°
        min_speakers: ìµœì†Œ í™”ì ìˆ˜
        max_speakers: ìµœëŒ€ í™”ì ìˆ˜
        
    Returns:
        í™”ìë¶„ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        print(f" í™”ìë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {audio_path}")
        
        # SpeakerDiarizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        diarizer = SpeakerDiarizer(
            token=token,
            min_speakers=min_speakers,
            max_speakers=max_speakers
        )
        
        # í™”ìë¶„ë¦¬ ìˆ˜í–‰
        segments = diarizer.diarize_speakers(audio_path)
        
        if not segments:
            return {
                "success": False,
                "error": "í™”ìë¶„ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤",
                "speaker_count": 0,
                "total_duration": 0.0,
                "segments": [],
                "timestamp": datetime.now().isoformat(),
                "processing_method": "failed"
            }
        
        # ê²°ê³¼ ì •ë¦¬
        speaker_count = len(set(seg['speaker_id'] for seg in segments))
        total_duration = max(seg['end'] for seg in segments) if segments else 0.0
        
        # ì„¸ê·¸ë¨¼íŠ¸ í˜•ì‹ ë³€í™˜
        formatted_segments = []
        for seg in segments:
            formatted_segments.append({
                "start_time": seg['start'],
                "end_time": seg['end'],
                "duration": seg['duration'],
                "speaker_id": seg['speaker_id'],
                "speaker": seg['speaker']
            })
        
        print(f"âœ… í™”ìë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {speaker_count}ëª…, {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        return {
            "success": True,
            "speaker_count": speaker_count,
            "total_duration": total_duration,
            "segments": formatted_segments,
            "timestamp": datetime.now().isoformat(),
            "processing_method": "pyannote" if diarizer.use_pyannote else "fallback"
        }
        
    except Exception as e:
        print(f"âŒ í™”ìë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "speaker_count": 0,
            "total_duration": 0.0,
            "segments": [],
            "timestamp": datetime.now().isoformat(),
            "processing_method": "error"
        }