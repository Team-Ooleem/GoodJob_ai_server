from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
from app.core.speaker_diarization import process_audio_pipeline
import tempfile
import requests
import os
import base64
from app.core.speaker_diarization import SpeakerDiarizer, download_audio_from_gcs
from datetime import datetime

router = APIRouter(prefix="/diarization", tags=["diarization"])

class DiarizationRequest(BaseModel):
    audio_url: str
    min_speakers: int = 1
    max_speakers: int = 2

class DiarizationResponse(BaseModel):
    success: bool
    speaker_count: int
    total_duration: float
    segments: list
    timestamp: str
    processing_method: str

@router.get("/test")
async def test():
    return {"message": "í™”ìë¶„ë¦¬ ê¸°ëŠ¥ ì¤€ë¹„ ì¤‘"}

@router.post("/analyze", response_model=DiarizationResponse)
async def analyze_speakers(request: DiarizationRequest):
    """
    GCS URLì—ì„œ í™”ìë¶„ë¦¬ë§Œ ìˆ˜í–‰
    
    Args:
        request: ì˜¤ë””ì˜¤ URL ë° ì„¤ì •
        
    Returns:
        í™”ìë¶„ë¦¬ ê²°ê³¼
    """
    try:
        # 1. GCSì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        print(f"ğŸµ GCSì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ: {request.audio_url}")
        response = requests.get(request.audio_url, timeout=300)
        response.raise_for_status()
        
        # 2. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tmp:
            tmp.write(response.content)
            tmp.flush()
            audio_path = tmp.name
        
        try:
            token = os.getenv("HF_TOKEN")
            if not token:
                print("âš ï¸ HF_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fallback ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                token = ""
            # 4. í™”ìë¶„ë¦¬ë§Œ ì‹¤í–‰
            results = process_audio_pipeline(
                audio_path,
                token=token,
                min_speakers=request.min_speakers,
                max_speakers=request.max_speakers
            )
            
            # 5. ì‘ë‹µ í˜•ì‹ ë§ì¶”ê¸°
            if results.get("success", False):
                return DiarizationResponse(
                    success=True,
                    speaker_count=results.get("speaker_count", 0),
                    total_duration=results.get("total_duration", 0.0),
                    segments=results.get("segments", []),
                    timestamp=results.get("timestamp", ""),
                    processing_method=results.get("processing_method", "unknown")
                )
            else:
                raise HTTPException(status_code=500, detail=results.get("error", "í™”ìë¶„ë¦¬ ì‹¤íŒ¨"))
            
        finally:
            # 6. ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(audio_path):
                os.unlink(audio_path)
                
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í™”ìë¶„ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.post("/get-segments-from-gcs", response_model=DiarizationResponse)
async def get_segments_from_gcs(
    gcs_url: str = Form(...),
    token: str = Form(...),
    canvas_id: str = Form(...),
    mentor_idx: int = Form(...),  # 101 (ê¹€ì½”ì¹˜)
    mentee_idx: int = Form(...),  # 202 (ì´ë©˜í‹°)
    session_start_offset: float = Form(default=0.0)
):
    try:
        print(f"ï¿½ï¿½ pynote GCS ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ì‹œì‘: {gcs_url}")
        print(f"ğŸ“‹ ë©˜í†  ID: {mentor_idx}, ë©˜í‹° ID: {mentee_idx}")
        
        # 1. GCSì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        audio_data = download_audio_from_gcs(gcs_url)
        print(f"âœ… GCS ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(audio_data)} bytes")
        
        # 2. pyannoteë¡œ í™”ìë¶„ë¦¬
        diarizer = SpeakerDiarizer(token=token)
        segments = diarizer.diarize_audio(audio_data)
        print(f"ï¿½ï¿½ í™”ìë¶„ë¦¬ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        # ğŸ†• 3. ë©˜í† /ë©˜í‹° ì •ë³´ë¥¼ í™œìš©í•œ ì •í™•í•œ ë§¤í•‘
        mapped_segments = diarizer.map_speakers_to_mentor_mentee(
            segments, mentor_idx, mentee_idx
        )
        print(f"ï¿½ï¿½ ìŠ¤í”¼ì»¤ ë§¤í•‘ ì™„ë£Œ: {len(mapped_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        # 4. ì„¸ê·¸ë¨¼íŠ¸ë³„ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        segment_buffers = []
        for i, segment in enumerate(mapped_segments):
            try:
                audio_buffer = diarizer.extract_audio_segment(
                    audio_data, 
                    segment['start_time'], 
                    segment['end_time']
                )
                
                segment_buffers.append({
                    'audioBuffer': base64.b64encode(audio_buffer).decode('utf-8'),
                    'startTime': segment['start_time'],
                    'endTime': segment['end_time'],
                    'speakerTag': segment['speaker_tag']  # 0=ë©˜í† (ê¹€ì½”ì¹˜), 1=ë©˜í‹°(ì´ë©˜í‹°)
                })
                
                print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {i+1} ì²˜ë¦¬ ì™„ë£Œ: {segment['start_time']:.1f}s-{segment['end_time']:.1f}s, í™”ì: {segment['speaker_tag']}")
                
            except Exception as segment_error:
                print(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {segment_error}")
                continue
        
        print(f"ï¿½ï¿½ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {len(segment_buffers)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë°˜í™˜")
        
        return {
            "success": True,
            "speaker_count": len(set(seg['speakerTag'] for seg in segment_buffers)),
            "total_duration": max(seg['endTime'] for seg in segment_buffers) if segment_buffers else 0.0,
            "segments": segment_buffers,
            "timestamp": datetime.now().isoformat(),
            "processing_method": "accurate_mentor_mentee_mapping"
        }
        
    except Exception as e:
        print(f"âŒ pynote ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "speaker_count": 0,
            "total_duration": 0.0,
            "segments": [],
            "timestamp": datetime.now().isoformat(),
            "processing_method": "mapping_failed"
        }